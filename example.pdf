{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.keras.layers as layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "np.random.randn()\n",
        "\n",
        "NUM_BATCHES = 600\n",
        "BATCH_SIZE = 512\n",
        "PLOT_EVERY = 1\n",
        "GRID_RESOLUTION = 400\n",
        "LATENT_DIM = 1\n",
        "\n",
        "def uniform_to_normal(z):\n",
        "    '''\n",
        "    Map a value from ~U(-1, 1) to ~N(0, 1)\n",
        "    '''\n",
        "    norm = stats.norm(0, 1)\n",
        "    return norm.ppf((z+1)/2)\n",
        "\n",
        "def generate_noise(samples, dimensions=2):\n",
        "    '''\n",
        "    Generate a matrix of random noise in [-1, 1] with shape (samples, dimensions)\n",
        "    '''\n",
        "    return np.random.uniform(-1, 1, (samples, dimensions))\n",
        "\n",
        "\n",
        "def build_generator(LATENT_DIM, output_dim):\n",
        "    '''\n",
        "    Build a generator mapping (R, R) to ([-1,1], [-1,1])\n",
        "    '''\n",
        "    input_layer = layers.Input((LATENT_DIM,))\n",
        "    X = input_layer\n",
        "    for i in range(4):\n",
        "        X = layers.Dense(16)(X)\n",
        "        X = layers.LeakyReLU(0.1)(X)\n",
        "        output_layer = layers.Dense(output_dim)(X)\n",
        "        G = Model(input_layer, output_layer)\n",
        "        return G\n",
        "\n",
        "\n",
        "def build_discriminator(dim):\n",
        "    '''\n",
        "    Build a discriminator mapping (R, R) to [0, 1]\n",
        "    '''\n",
        "    input_layer = layers.Input((dim,))\n",
        "    X = input_layer\n",
        "    for i in range(2):\n",
        "        X = layers.Dense(64)(X)\n",
        "        X = layers.LeakyReLU(0.1)(X)\n",
        "    output_layer = layers.Dense(1, activation='sigmoid')(X)\n",
        "    D = Model(input_layer, output_layer)\n",
        "    D.compile(Adam(learning_rate=0.002, beta_1=0.5),\n",
        "                        loss='binary_crossentropy',\n",
        "                        metrics=['accuracy'])\n",
        "    return D\n",
        "\n",
        "def build_GAN(G, D, LATENT_DIM):\n",
        "    '''\n",
        "    Given a generator and a discriminator, build a GAN\n",
        "    '''\n",
        "    D.trainable = False\n",
        "    input_layer = layers.Input((LATENT_DIM,))\n",
        "    X = G(input_layer)\n",
        "    output_layer = D(X)\n",
        "    GAN = Model(input_layer, output_layer)\n",
        "    GAN.compile(Adam(learning_rate=0.001, beta_1=0.5),\n",
        "                        loss='binary_crossentropy',\n",
        "                        metrics=['accuracy'])\n",
        "    return GAN\n",
        "\n",
        "\n",
        "G.trainable_variables\n",
        "\n",
        "\n",
        "### Visualizations\n",
        "grid_latent = np.linspace(-1, 1, 203)[1:-1].reshape((-1, 1))\n",
        "grid_sample = np.linspace(-3, 3, 603)[1:-1].reshape((-1, 1))\n",
        "test_noise = generate_noise(5000, LATENT_DIM)\n",
        "test_samples = uniform_to_normal(test_noise)\n",
        "def plot(G, D, step, step_count, D_accuracy, D_loss, G_accuracy, G_loss, filename):\n",
        "    '''\n",
        "    Plots for the GAN gif\n",
        "    '''\n",
        "    f, ax = plt.subplots(2, 2, figsize=(8,8))\n",
        "    f.suptitle(f'\\n       {step:05d}', fontsize=10)\n",
        "\n",
        "\n",
        "    # [0, 0]: plot loss and accuracy\n",
        "    ax[0, 0].plot(step_count,\n",
        "                    G_loss,\n",
        "                    label='G loss',\n",
        "                    c='darkred',\n",
        "                    zorder=50,\n",
        "                    alpha=0.8,)\n",
        "    ax[0, 0].plot(step_count,\n",
        "                    G_accuracy,\n",
        "                    label='G accuracy',\n",
        "                    c='lightcoral',\n",
        "                    zorder=40,\n",
        "                    alpha=0.8,)\n",
        "    ax[0, 0].plot(step_count,\n",
        "                    D_loss,\n",
        "                    label='D loss',\n",
        "                    c='darkblue',\n",
        "                    zorder=55,\n",
        "                    alpha=0.8,)\n",
        "    ax[0, 0].plot(step_count,\n",
        "                    D_accuracy,\n",
        "                    label='D accuracy',\n",
        "                    c='cornflowerblue',\n",
        "                    zorder=45,\n",
        "                    alpha=0.8,)\n",
        "    ax[0, 0].set_xlim(-5, max(max(step_count), NUM_BATCHES)+5)\n",
        "    ax[0, 0].set_ylim(-0.05, 1.55)\n",
        "    ax[0, 0].set_xlabel('Epoch')\n",
        "    ax[0, 0].legend(loc=1)\n",
        "\n",
        "    # [0, 1]: Plot actual samples and fake samples\n",
        "\n",
        "    fake_samples = G.predict(test_noise, batch_size=len(test_noise))\n",
        "    x_vals = np.linspace(-3, 3, 301)\n",
        "    y_vals = stats.norm(0,1).pdf(x_vals)\n",
        "    ax[0, 1].plot(x_vals, y_vals, color='blue', label='real')\n",
        "    ax[0, 1].fill_between(x_vals, np.zeros(len(x_vals)), y_vals, color='blue', alpha=0.6)\n",
        "    ax[0, 1].set_xlim(-3, 3)\n",
        "    ax[0, 1].set_ylim(0, 0.82)\n",
        "    ax[0, 1].legend(loc=1)\n",
        "    ax[0, 1].set_xlabel('Sample Space')\n",
        "    ax[0, 1].set_ylabel('Probability Density')\n",
        "\n",
        "\n",
        "    # [1, 0]: Confident real input\n",
        "    grid_latent = np.linspace(-1, 1, 103)[1:-1].reshape((-1, 1))\n",
        "    true_mappings = uniform_to_normal(grid_latent)\n",
        "    GAN_mapping = G.predict(grid_latent)\n",
        "    ax[1, 0].scatter(grid_latent.flatten(), true_mappings.flatten(),\n",
        "                edgecolor='blue', facecolor='None', s=5, alpha=1,\n",
        "                linewidth=1, label='Real Mapping')\n",
        "    ax[1, 0].scatter(grid_latent.flatten(), GAN_mapping.flatten(),\n",
        "                edgecolor='red', facecolor='None', s=5, alpha=1,\n",
        "                linewidth=1, label='GAN Mapping')\n",
        "    ax[1, 0].legend(loc=8)\n",
        "    ax[1, 0].set_xlim(-1, 1)\n",
        "    ax[1, 0].set_ylim(-3, 3)\n",
        "    ax[1, 0].set_xlabel('Latent Space')\n",
        "    ax[1, 0].set_ylabel('Sample Space')\n",
        "\n",
        "    # [1, 1]: Confident real ouput\n",
        "    confidences = D.predict(grid_sample, batch_size=BATCH_SIZE).flatten()\n",
        "    ax[1, 1].plot(grid_sample.flatten(), confidences, c='k')\n",
        "    lower, upper = -3, 3\n",
        "    for i in range(0, len(confidences), 50):\n",
        "        if i ==0:\n",
        "            continue\n",
        "        ax[1, 1].plot([i / len(confidences) * (upper - lower) + lower, ]*2,\n",
        "                        [0, confidences[i]], c='k')\n",
        "    ax[1, 1].plot([lower, lower, upper, upper], [confidences[0], 0, 0, confidences[-1]], c='k')\n",
        "    ax[1, 1].fill_between(grid_sample.flatten(), np.zeros(len(confidences)), confidences, color='k', alpha=0.6)\n",
        "    ax[1, 1].set_xlabel('Sample Space Value')\n",
        "    ax[1, 1].set_ylabel('Discriminator Confidence')\n",
        "    ax[1, 1].set_xlim(lower, upper)\n",
        "    ax[1, 1].set_ylim(-0.00, 1.00)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(filename)\n",
        "    plt.close()\n",
        "    return\n",
        "\n",
        "\n",
        "## Set up directories\n",
        "paths = ['ims',\n",
        "        'ims/1_1D_normal',\n",
        "            'ims/1_1D_normal/a',\n",
        "            'ims/1_1D_normal/b',\n",
        "            'ims/1_1D_normal/c',\n",
        "        ]\n",
        "for i in paths:\n",
        "    if not os.path.exists(i):\n",
        "        os.makedirs(i)\n",
        "\n",
        "## Part 1b: 1D uniform to 1D normal GAN\n",
        "### Setup\n",
        "\n",
        "test_noise = generate_noise(1000, LATENT_DIM)\n",
        "test_samples = uniform_to_normal(test_noise)\n",
        "G = build_generator(LATENT_DIM, 1)\n",
        "D = build_discriminator(1)\n",
        "GAN = build_GAN(G, D, LATENT_DIM)\n",
        "\n",
        "\n",
        "G.weights\n",
        "\n",
        "step_count = []\n",
        "D_accuracy = []\n",
        "G_accuracy = []\n",
        "D_loss = []\n",
        "G_loss = []\n",
        "count = 0\n",
        "for step in range(NUM_BATCHES):\n",
        "    print(f'1b: {step}/{NUM_BATCHES}', end='\\r')\n",
        "    # Train discriminator\n",
        "    D.trainable = True\n",
        "    real_data = uniform_to_normal(generate_noise(BATCH_SIZE // 2, LATENT_DIM))\n",
        "    fake_data = G.predict(generate_noise(BATCH_SIZE // 2, LATENT_DIM), batch_size=BATCH_SIZE // 2)\n",
        "    data = np.concatenate((real_data, fake_data), axis=0)\n",
        "    real_labels = np.ones((BATCH_SIZE // 2, 1))\n",
        "    fake_labels = np.zeros((BATCH_SIZE // 2, 1))\n",
        "    labels = np.concatenate((real_labels, fake_labels), axis=0)\n",
        "    _D_loss, _D_accuracy = D.train_on_batch(data, labels)\n",
        "\n",
        "    # Train generator\n",
        "    D.trainable = False\n",
        "    noise = generate_noise(BATCH_SIZE, LATENT_DIM)\n",
        "    labels = np.ones((BATCH_SIZE, 1))\n",
        "    _G_loss, _G_accuracy = GAN.train_on_batch(noise, labels)\n",
        "\n",
        "    if step % PLOT_EVERY == 0:\n",
        "        step_count.append(step)\n",
        "        D_loss.append(_D_loss)\n",
        "        D_accuracy.append(_D_accuracy)\n",
        "        G_loss.append(_G_loss)\n",
        "        G_accuracy.append(_G_accuracy)\n",
        "        plot(G=G,\n",
        "             D=D,\n",
        "             step=step+1,\n",
        "             step_count=step_count,\n",
        "             D_accuracy=D_accuracy,\n",
        "             D_loss=D_loss,\n",
        "             G_accuracy=G_accuracy,\n",
        "             G_loss=G_loss,\n",
        "             filename=f'ims/1_1D_normal/b/1b.{count:03d}.png')\n",
        "        count += 1\n",
        "print()\n",
        "os.system(f'ffmpeg -r 20 -i ims/1_1D_normal/b/1b.%03d.png'\n",
        "              f' -crf 15 ims/1_1D_normal/b/1b.mp4')\n",
        "\n",
        "total_steps = 30000\n",
        "for step in range(NUM_BATCHES, total_steps):\n",
        "    print(f'1c: {step}/{total_steps}', end='\\r')\n",
        "    # Train discriminator\n",
        "    D.trainable = True\n",
        "    real_data = uniform_to_normal(generate_noise(BATCH_SIZE // 2, LATENT_DIM))\n",
        "    fake_data = G.predict(generate_noise(BATCH_SIZE // 2, LATENT_DIM), batch_size=BATCH_SIZE // 2)\n",
        "    data = np.concatenate((real_data, fake_data), axis=0)\n",
        "    real_labels = np.ones((BATCH_SIZE // 2, 1))\n",
        "    fake_labels = np.zeros((BATCH_SIZE // 2, 1))\n",
        "    labels = np.concatenate((real_labels, fake_labels), axis=0)\n",
        "    _D_loss, _D_accuracy = D.train_on_batch(data, labels)\n",
        "\n",
        "    # Train generator\n",
        "    D.trainable = False\n",
        "    noise = generate_noise(BATCH_SIZE, LATENT_DIM)\n",
        "    labels = np.ones((BATCH_SIZE, 1))\n",
        "    _G_loss, _G_accuracy = GAN.train_on_batch(noise, labels)\n",
        "\n",
        "    if step % PLOT_EVERY == 0:\n",
        "        step_count.append(step)\n",
        "        D_loss.append(_D_loss)\n",
        "        D_accuracy.append(_D_accuracy)\n",
        "        G_loss.append(_G_loss)\n",
        "        G_accuracy.append(_G_accuracy)\n",
        "\n",
        "plot(G=G,\n",
        "     D=D,\n",
        "     step=step+1,\n",
        "     step_count=step_count,\n",
        "     D_accuracy=D_accuracy,\n",
        "     D_loss=D_loss,\n",
        "     G_accuracy=G_accuracy,\n",
        "     G_loss=G_loss,\n",
        "     filename=f'ims/1_1D_normal/c/1c.{total_steps:03d}.png')\n",
        "G.save(\"ims/1_1D_normal/c/G.h5\")\n",
        "D.save(\"ims/1_1D_normal/c/D.h5\")\n",
        "\n",
        "\n",
        "grid_latent = np.linspace(-1, 1, 1003)[1:-1].reshape((-1, 1))\n",
        "true_mappings = uniform_to_normal(grid_latent)\n",
        "\n",
        "\n",
        "GAN_mapping = G.predict(grid_latent)\n",
        "def give_histogram(samples,bins=100):\n",
        "    c,b = np.histogram(samples,bins=bins,density=True)\n",
        "    w = b[1]-b[0]\n",
        "    x = np.linspace(np.min(b),np.max(b),bins)\n",
        "    return x,c,w\n",
        "\n",
        "len(G_loss)\n",
        "plt.plot(D_loss)\n",
        "\n",
        "x,c,w = give_histogram(GAN_mapping.squeeze())\n",
        "xa,ca,wa = give_histogram(true_mappings.squeeze())\n",
        "ax=plt.subplot()\n",
        "ax.bar(x,c,width=w, color=\"red\")\n",
        "ax.bar(xa,ca,width=wa, color=\"blue\")\n",
        "\n",
        "\n",
        "plt.hist(GAN_mapping.squeeze(),bins=50)\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(grid_latent.flatten(), true_mappings.flatten(),\n",
        "            edgecolor='blue', facecolor='None', s=5, alpha=1,\n",
        "            linewidth=1, label='Inverse CDF Mapping')\n",
        "plt.scatter(grid_latent.flatten(), GAN_mapping.flatten(),\n",
        "            edgecolor='red', facecolor='None', s=5, alpha=1,\n",
        "            linewidth=1, label='Inverse CDF Mapping')\n",
        "plt.xlim(-1, 1)\n",
        "plt.ylim(-4, 4)\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'ims/1_1D_normal/c/1c.true.png')\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "argv": [
        "/usr/bin/python3",
        "-m",
        "ipykernel_launcher",
        "-f",
        "{connection_file}"
      ],
      "display_name": "qenv",
      "language": "python",
      "metadata": {
        "debugger": true
      },
      "name": "qenv"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}